static_dir = "../client/dist"
log_dir = "logs/moshi-server-rust/stt"
instance_name = "config-stt-en_fr-lowram-sm75"
# Authentication is handled by Better Auth JWT (BETTER_AUTH_SECRET env var)
authorized_ids = []

[modules.asr]
path = "/api/asr-streaming"
type = "BatchedAsr"
# Using pre-converted FP16 model for SM 7.5 (Turing) GPUs that lack native BF16.
# F16 provides memory savings while avoiding the BF16 kernel issues.
# Generated via: cargo run --bin sm75-prep -- --output assets/fp16/stt-1b-en_fr-candle.fp16.safetensors
lm_model_file = "assets/fp16/stt-1b-en_fr-candle.fp16.safetensors"
text_tokenizer_file = "hf://kyutai/stt-1b-en_fr-candle/tokenizer_en_fr_audio_8000.model"
audio_tokenizer_file = "hf://kyutai/stt-1b-en_fr-candle/mimi-pytorch-e351c8d8@125.safetensors"
asr_delay_in_tokens = 6
# batch_size is auto-adjusted based on available VRAM; 64 is a safe upper bound.
# Default model size is 1.0B. For stt-2.6b models, set MOSHI_MODEL_PARAMS_BILLIONS=2.6
batch_size = 4
conditioning_learnt_padding = true
temperature = 0.0
# Explicit F16 to match the pre-converted model weights.
dtype_override = "f32"

[modules.asr.model]
audio_vocab_size = 2049
text_in_vocab_size = 8001
text_out_vocab_size = 8000
audio_codebooks = 32

[modules.asr.model.transformer]
d_model = 2048
num_heads = 16
num_layers = 16
dim_feedforward = 8192
causal = true
norm_first = true
bias_ff = false
bias_attn = false
context = 750
max_period = 100000
use_conv_block = false
use_conv_bias = true
gating = "silu"
norm = "RmsNorm"
positional_embedding = "Rope"
conv_layout = false
conv_kernel_size = 3
kv_repeat = 1
max_seq_len = 40960

[modules.asr.model.extra_heads]
num_heads = 4
dim = 6
